---
title : \[ML with Python\] 4장 데이터 표현과 특성 공학 - 특성 자동 선택
category :
  - ML
tag :
  - python
  - deep-learning
  - AI
  - machine learning
  - 머신러닝
  - 데이터 전처리
  - 입문
  - subinium
  - 소스코드

sidebar:
  nav: sidebar-MLwithPython

use_math : true

header:
  teaser : /assets/images/category/ml.jpg
  overlay_color: "#AF3D8A"
published : false
---

4.5 특성 자동 선택

> 본 문서는 [파이썬 라이브러리를 활용한 머신러닝] 책을 기반으로 하고 있으며, subinium(본인)이 정리하고 추가한 내용입니다. 생략된 부분과 추가된 부분이 있으니 추가/수정하면 좋을 것 같은 부분은 댓글로 이야기해주시면 감사하겠습니다.

새로운 특성을 만드는 방법이 많으므로 데이터의 차원이 원본 특성의 수 이상으로 증가하기 쉽습니다.
그러나 특성이 추가될 수록 모델은 복잡해지고 과대적합될 가능성도 높아집니다.

새로운 특성을 추가하거나 고차원 데이터셋을 사용할 때, 가장 유용한 특성만 선택하고 나머지는 무시해서 특성의 수를 줄이는 것이 좋습니다.
이렇게 해야만 일반화 성능이 올라갑니다. 하지만 어떤 특성이 좋은지 어떻게 알 수 있을까요?

여기에는 총 3가지 방법이 있습니다.

- 일변량 통계
- 모델 기반 특성 선택
- 반복적 특성 선택

이 방법들은 모두 지도 학습 방법이므로 최적값을 찾으려면 타깃값이 필요합니다.
그리고 데이터를 훈련 세트와 테스트 세트로 나눈 다음 훈련 데이터만 특성 선택에 사용해야 합니다.

> **NOTE** 훈련 데이터만 특성 선택에 사용하는 이유는 데이터 누설 때문입니다. 이는 후에 다루도록 하겠습니다.

## 4.5.1 일변량 통계

일변량 통계에서는 개개의 특성과 타깃 사이에 중요한 통계적 관계가 있는지를 계산합니다
그리고 깊게 관련되어 있다고 판단되는 특성을 선택합니다.

> **NOTE** 분류에서는 **분산분석**(ANOVA, analysis of variance)라고도 합니다. 데이터를 클래스별로 나누어 평균을 비교하는 방법입니다.

이 방법의 핵심은 **일변량** 입니다. 즉, 각 특성이 독립적으로 평가된다는 점입니다. 따라서 다른 특성과 깊게 연관된 특성은 선택되지 않을 것입니다.
일변량 분석은 계산이 매우 빠르고 평가를 위해 모델을 만들 필요가 없습니다.
한편으로 이 방식은 특성을 선택한 후 적용하려는 모델에 상관없이 사용할 수 있습니다.

scikit-learn에서 일변량 분석으로 특성을 선택하려면 분류에서는 f_classif(기본값)를, 회귀에서는  f_regression을 보통 선택하여 테스트하고, 계산한 p-값(p-value)에 기초하여 특성을 제외하는 방식을 선택합니다.

이런 방식들은 매우 높은 p-값을 가진 특성을 제외할 수 있도록 임계값을 조정하는 매개변수를 사용합니다.

## 4.5.2 모델 기반 특성 선택

## 4.5.3 반복적 특성 선택
