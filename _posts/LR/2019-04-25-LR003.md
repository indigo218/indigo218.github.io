---
title : "[LR#003] Automated Deep Photo Style Transfer"
category :
  - LR
tag :
  - Style Transfer
  - Deep Learning
sidebar:
  nav: sidebar-youtube
use_math : true
header:
  overlay_image : "http://www.lighting-inspiration.com/wp-content/uploads/2015/08/Lighting-Inspiration.com_Rohinni-Lightpaper1.jpg"
  overlay_color : "#E0BBE4"
---

사진에 사진을 입힌다.

LR의 세 번째는 색칠에 관한 paper 입니다.

글 제목과 같이 논문의 제목은 **Automated Deep Photo Style Transfer** 입니다. 2019년 1월에 업로드된 paper입니다.

제가 딥러닝을 공부하며 제일 흥미로웠던 Style Transfer 관련 최신 논문입니다.

원래는 2017년 3월에 업로드된 논문인 [**Deep Photo Style Transfer**](https://arxiv.org/abs/1703.07511) 을 리뷰할까 했는데, 이와 관련 논문을 찾아보니 Automated가 붙은 논문이 있어 이 논문으로 선택했습니다.

각각의 논문과 구현 코드는 다음 링크를 통해서 확인할 수 있습니다.

- [paper link](https://arxiv.org/abs/1901.03915)

- [github link](https://github.com/Spenhouet/automated-deep-photo-style-transfer)

Tensorflow로 구현했다고 합니다.

## I. 초록으로 먼저 읽기

Photorealism은 수학적으로 공식화하기는 복잡한 개념입니다. (포토리얼리즘은 그림, 드로잉, 그래픽 미디어를 다른 미디어를 이용해 최대한 현실적으로 이미지를 재현하는 예술 분야입니다.)

이 논문에서 사용되는 기술은 Deep Photo Style Transfer은 Photorealism을 유지하면서 참조 이미지의 스타일을 목표 이미지(content image)에 입히는 것을 목표로 합니다.

이미지의 (의미적으로 다른) 부분에 대해서 스타일 전송을 독립적으로 적용함으로 이미지의 왜곡을 방지합니다.

추가적으로 신경망 기반의 자동화된 세분화 작업을 진행합니다.(Semantic Segmentation)
결과를 더욱 향상시키기 위해 이미지 미학에 대한 척도가 사용되고 정교합니다. (NIMA)

이미지 세분화의 자동화로 파이프 라인은 사용자 상호 작용과 완전히 독립적으로되어 새로운 애플리케이션을 허용합니다.

## II. 추가 내용

### Introduction

**Neural Style Transfer** 는 2015년에 나온 이 [논문](https://www.robots.ox.ac.uk/~vgg/rg/papers/1508.06576v2.pdf)에서 처음 소개된 기술입니다. 이미지 스타일을 다른 이미지로 전송하는 방법입니다.

Neural Style Transfer는 초기 노이즈 이미지를 반복적으로 업데이트하여 예술적 스타일을 다른 이미지로 전송합니다.

**Deep Photo Style Transfer** 는 이 [논문](https://arxiv.org/abs/1703.07511)에서 처음 소개되었습니다. 위 기술을 바탕으로 만든 기술로 image context에서 color space 공간에 제한적으로 스타일 전송을 하여 이미지에 기술을 적용합니다.

이 논문은 위 논문에서 자동 세분화와 의미론적 그룹화를 도입하였습니다. 또한 **Neural Image Assessment** 을 활용해 이미지 미학을 향상시켰습니다.

이 논문을 통해 향상된 결과는 다음과 같습니다.

<figure>

<img src ="https://i.imgur.com/mKTAY3H.png">
<figcaption> 향상된 결과 예시 </figcaption>

</figure>

### 이미지 정보

ImageNet에서 훈련한 VGG19의 활성화 레이어를 이용해 이미지의 정보를 가져옵니다.

### 스타일 손실

기존 논문은 전체 이미지에서 conv layer을 통해 스타일 손실이 계산됩니다. 하지만 이 경우, 이미지의 의미론적 영역을 고려하지 않습니다, 이것은 텍스쳐가 이상한 곳에 매핑될 수 있습니다. (하늘에 건물 질감이 입혀진다던지 등등)

semantic segmentation을 통해 세분화된 의미론적인 분류를 통해 별도의 스타일 손실을 공식화합니다.

### Photorealism 규제

이 부분에 대해서는 수학적으로 완벽하게 할 수는 없지만 국부적인 아핀 변환에 기반한 손실 함수를 사용헀다고 합니다.

> 이 부분은 이해하기가 조금 어렵네요. 논문을 더 읽어봐야겠습니다.

### 최적화

optimization은 Adam optimization을 사용합니다.

![스크린샷 2019-04-25 오후 12.17.33](https://i.imgur.com/7Ac3ctn.png)

### 이미지 자동 세분화

이미지는 의미에 따라 세분화가 이뤄져야합니다.
기존 논문에서는 수동으로 이를 세분화했습니다.

**Neural segmentation** : ADE20K 데이터셋에서 훈련한 Pyramid Scene Parsing Network (PSPNet)을 사용합니다.

**Semantic Grouping** : 위를 이용해 나누고 **Sematch** 라이브러리로 의미가 비슷한 클래스를 합칩니다.

![Sematch](https://i.imgur.com/u6Hkgul.png)

### NIMA : Image Assessment Loss

이미지의 퀄리티 측정(노이즈, 아티팩트)을 위해 **Neural Image Assessment(NIMA)** 를 사용합니다. 여기서 score를 측정하고 loss를 계산해서 사진의 퀄리티를 높입니다.


### 여러 결과물

한 사진당 걸린 시간은 16분이라고 합니다.

<figure>
<img src = "https://i.imgur.com/Af3GoQH.png">

<figcaption> 상세한 명세 감사합니다. </figcaption>
</figure>

<figure class = "half">
<img src = "https://i.imgur.com/GGliBid.jpg">
<img src = "https://i.imgur.com/aktwQoo.jpg">
<figcaption> 저는 자동차 사진이 제일 멋진 것 같습니다. </figcaption>
</figure>

## III. 결론

여전히 해상도 개선이 필요한 작업이라고 합니다. 하지만 많은 접근법이 새로운 것 같습니다.

딥러닝은 아이디어의 학문인 것 같습니다. 규제/제한, 분야, 방법론 등 볼때마다 새롭네요.
이 기술과 최근 NVIDIA에서 발표한 프로젝트와 결합해도 재미있을 것 같습니다.

+ 이번 논문을 통해서 논문에서 설명에 도표와 예시가 얼마나 중요한지 한번 더 깨달았습니다.
