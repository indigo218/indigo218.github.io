---
title : "[LR#005] Style Transfer by Relaxed Optimal Transport and Self-Similarity"
category :
  - LR
tag :
  - sketch
  - Deeplearning
  - colorization
sidebar:
  nav: sidebar-youtube
use_math : true
header:
  overlay_image : "http://www.lighting-inspiration.com/wp-content/uploads/2015/08/Lighting-Inspiration.com_Rohinni-Lightpaper1.jpg"
  overlay_color : "#E0BBE4"
---
style transfer에서 새롭게 정의하기

style transfer에서 새로운 논문이 나와서 가볍게 리뷰해봤습니다.

논문 제목은 **Style Transfer by Relaxed Optimal Transport and Self-Similarity** 이며, 2019년 4월 말에 업로드된 논문입니다.

Style Transfer의 성능 자체도 높고, 속도도 빠르고, 방식도 기존과는 다른 부분이 있어 가져왔습니다. 아직 GUI 자체가 편리한 것은 아니지만, 그래도 사용자 설정하는 것만 아니면 웹 데모 자체는 편한 것 같습니다.

구체적으로 식을 읽지 않았지만 손실 함수를 새롭게 근사식을 찾아 진행하는 방식이 신기합니다. EMD 방법도 저는 처음 봤기에...

논문, 깃헙, 데모는 다음 링크에 있습니다.

- paper : https://arxiv.org/pdf/1904.12785.pdf
- gihub : https://github.com/nkolkin13/STROTSS
- web demo : http://128.135.245.233:8080/

## 초록으로 읽기

스타일 트랜스퍼 알고리즘은 다른 이미지의 스타일을 사용하여 한 이미지의 내용을 렌더링하려고 노력합니다.

본 논문에서는 새로운 최적화 기반 스타일 트랜스퍼 알고리즘인 Relaxed Optimal Transport and Self-Similarity (STROTSS)를 제안합니다.

스타일 이미지와 출력 간의 시각적 유사성에 대해 point-to-point나 region-to-region을 사용자가 제어하도록 메서드를 확장합니다.

이는 특정 시각 효과나 오류 수정 등에 있어 유용합니다.

이전 연구와 정량적인 비교를 위해, large-scale user study를 수행합니다.

본 논문의 결과는 콘텐츠 보존 측면에서 이전의 방법보다 더 나은 품질을 제공합니다.

<figure>
    <img src = "https://i.imgur.com/jjJQQis.png">
    <figcaption> 왼쪽은 제한이 없이, 오른쪽은 제한을 통해 결과 생성 </figcaption>
</figure>

## 더 알아보기

<figure>
    <img src = "https://i.imgur.com/WSPLELT.jpg">
    <figcaption> 결과물 </figcaption>
</figure>

### Introduction

스타일을 심층신경망(deep neural network)에서 추출된 특성이라고 정의합니다. 그리고 이 추출된 특성 분포간의 거리를 the Earth Mover's Distance (EMD)의 효율적인 근사값으로 측정합니다.

이러한 정의는 스타일 유사성을 통계적으로 볼 수 있고, 직관적입니다.

스타일 전송의 목표는 스타일 이미지의 시각적 속성을 콘텐츠의 기본 레이아웃과 의미에 대한 왜곡을 최소화하면서 콘텐츠 이미지에 배치하는 것입니다. 본질적으로 이러한 시각적 속성을 '최적으로 전송'합니다.

콘텐츠에 대한 우리의 정의는 자기 유사성의 개념에 의해 영감을 얻었으며 인간의 지각 시스템은 절대적인 모습이 아닌 주변과의 상대적인 외관을 기반으로 객체를 식별하기 때문에 견고하다는 개념에 입각했습니다.

또한 스타일 트랜스퍼의 예술적 도구로의 유용성을 높이고, 사용자가 쉽고 직관적으로 제어 할 수 있는 것이 중요합니다.

Amazon Mechanical Turk (AMT)에서 일하는 662명의 평가를 통해 측정합니다. 측정은 콘텐츠 보존과 스타일 품질을 별개로 평가했습니다.

### More Detail Method

다음 사진은 RGB에서 코사인 유사도로 연관된 부분을 heatmap으로 표현한 결과입니다.
콘텐츠에서 유사한 1024개의 포인트를 뽑아서 사용합니다.

![RGB](https://i.imgur.com/B0ztRQp.png)

가장 낮은 해상도에서 스타일 이미지의 평균 색상에 추가 된 콘텐츠 이미지로 구성된 라플라시안 피라미드의 하단 수준을 사용하여 초기화합니다.

그런 다음 초기화 된 출력 이미지를 5 단계 라플라시안 피라미드로 분해하고 RMSprop을 사용하여 피라미드의 항목을 업데이트하여 스타일을 최소화하고 콘텐츠 손실을 계산하는 데 필요한 쌍 거리 계산은 입력의 모든 좌표에서 피쳐 추출을 배제합니다. 대신에 스타일 이미지에서 무작위로 1024 개의 좌표를 샘플링하고 콘텐츠 이미지에서 임의의 x, y 오프셋을 갖는 균일 한 격자에 1024 개의 좌표를 샘플링합니다. (즉 스타일에서는 랜덤하게 선택, 콘텐츠에는 규칙적으로 선택)

우리는 이러한 위치에서 추출한 특징을 제외하고 RMSprop의 각 단계 후에 이러한 위치를 다시 샘플링합니다.

### 결과 예시

![예시1](https://i.imgur.com/J7FuDUa.jpg)

### 지침 예시

![예시2](https://i.imgur.com/eECHnBP.png)

### $\alpha$ 값 예시

$\alpha$ 값에 따라 더 많은 스타일 트랜스퍼를 적용할 수 있습니다.

![alpha](https://i.imgur.com/Jw1lFW5.png)

### 측정 인터페이스

다음과 같은 방식으로 측정합니다.

![evaluate](https://i.imgur.com/pkEOOOp.png)

측정 결과는 다음과 같습니다.

![result](https://i.imgur.com/c43EWfN.png)

### 결과

![손실함수에 따른 변화](https://i.imgur.com/xcEbz6r.png)

### 환경 및 시간 측정

<figure class = "half">
    <img src = "https://i.imgur.com/nwYYmMX.png">
    <img src = "https://i.imgur.com/NqfFUAD.png">
    <figcaption> 시간 측정 </figcaption>
</figure>

## 결론

본 논문에서는 스타일 트랜스퍼를 위한 스타일과 내용의 새로운 공식화를 제안하고 최종 알고리즘이 이전의 작업과 비교하여 스타일적 품질(stylization queality)과 내용 보존면에서 향상된 것을 보였습니다.

또한 피쳐 분포 사이의 거리를 더 정확하게 측정하는 스타일-유사성(style-similarity) 손실이 더 나은 스타일 트랜스퍼를 유도한다는 것을 보여줍니다.

논문에서 사용하는 earth movers distance의 근사값은 간단하지만 효과적입니다. 더 정확한 근사는 향후 작업을 위해 남겨둡니다.

향후 연구를 위한 또 다른 방향은 제안된 목적 함수를 사용하여 feed-forward style transfer을 훈련하고, 속도를 향상시키는 것입니다.

## 추가적으로 생각하는 부분

아직 point-to-point나 region-to-region을 전달하는 방식이 비효율적입니다. 이런 부분을 GUI를 만들어 좋게 만들면 좋을 것 같습니다.

![방법](https://i.imgur.com/ejsW44B.png)
