---
title : "[LR#009] PaperRobot: Incremental Draft Generation of Scientific Ideas"
category :
  - LR
tag :
  - audio
  - GAN
  - music
  - wavenet
sidebar:
  nav: sidebar-youtube
use_math : true
header:
  overlay_image : "http://www.lighting-inspiration.com/wp-content/uploads/2015/08/Lighting-Inspiration.com_Rohinni-Lightpaper1.jpg"
  overlay_color : "#E0BBE4"
---
이제 논문도 AI가 써준다고??

논문을 쓰는 것은 매우 힘든 작업입니다. 하지만 이것도 AI가 해줄 수 있다면 어떨까요?

이런 논문 쓰기 AI를 연구한 논문이 2019년 5월 20일에 발표되어 이렇게 공유합니다.

논문 제목은 **PaperRobot: Incremental Draft Generation of Scientific Ideas** 입니다.

자연어 처리 분야에 지식이 많이 없어 보다 전문적으로 리뷰하지는 못했지만, 아이디어와 다양한 도메인에 대한 지식을 결합하는 과정이 인상적이네요.

아직 코드를 공개하지 않았지만, 후에 공개하지 않을까요.

paper : https://arxiv.org/pdf/1905.07870.pdf

github : https://github.com/EagleW/PaperRobot

## 초록으로 읽기

본 논문은 PaperRobot이라는 자동 연구 조교를 소개합니다.

1. 대상 도메인에서 사람이 쓴 논문을 대량으로 학습합니다. 그리고 포괄적인 background knowledge graphs(KGs)를 만듭니다.

2. graph attention과 context attention을 이용해 background KGs로부터 새로운 아이디어를 만듭니다.

3. memory-attention 네트워크를 기반으로 새로운 논문의 핵심 요소를 점진적으로 작성합니다. 입력 제목을 기반으로 초록, 결론, future work 그리고 future work에서 다음 논문 제목까지 생성합니다.

## 더 읽어보기

### 1. Introduction

본 연구의 (대망의) 목표는 PaperRobot을 구축하여 과학적 발견과 생산을 가속화하는 것입니다.
총 세 가지의 주요 과제를 다룹니다.

#### Read Existing Papers

과학연구에 종사하는 분들은 이제 논문이 너무 많다는 것을 알고 있습니다.
예시로 바이오메디컬 분야는 매년 평균 500,000 개 이상의 논문이 출판되고 있습니다.
2016년에만 총 1,200,000개의 논문이 출판되었고, 2014년 조사 결과 지금까지 출판된 논문 수는 약 2600만건을 넘었습니다.

하지만 인간의 독서 능력은 매년 비슷합니다. 2012년에 미국 과학자들은 평균적으로 연간 평균 264개의 논문을 읽었을 거라고 추정했습니다. 2005년 결과와 크게 차이가 없는 결과입니다.

PaperRobot은 이제 이런 논문들을 자동으로 읽고, background knowlege graphs(KGs)를 만듭니다. 각 노드는 entities/concepts이며, 엣지는 이들의 관계입니다.

#### Creat New Ideas

과학적 발견은 KGs에서 새로운 노드 또는 링크를 만드는 것으로 생각할 수 있습니다. **하지만** 새로운 노드를 만드는 것은 일반적으로 실험실에서 이뤄지는 행위이며, PaperRobot에게는 무리입니다.

하지만 KGs에서 새로운 엣지를 만드는 것은 보다 쉬운 일입니다. 2015년 논문에 따르면 바이오메디컬 분야의 640만개의 논문에서 60%가 incremental work라고 합니다. 여기서 연구팀은 KGs에서 새로운 링크를 예측함으로 새로운 아이디어와 가설의 점진적인 생성을 자동화할 수있다고 생각했습니다.

최근의 연구는 가중치의 결합으로 구축된 KGs를 기반으로 약물과 질병 논문간의 강한 관련성을 확인했습니다.

본 논문은 링크 예측을 위해 KG 구조와 구조화되지 않은 문맥 텍스트를 사용합니다.

#### Write a New Paper about New Idea

그리고 새로운 memory-attention 네트워크를 기반으로 새로운 논문의 핵심 요소를 점진적으로 작성합니다. 입력 제목을 기반으로 초록, 결론, future work 그리고 future work에서 다음 논문 제목까지 생성합니다.

그림으로 확인하면 다음과 같습니다.

![workflow](https://i.imgur.com/FCN4BVa.png)

사용 가능한 논문의 양이 많아 바이오메디컬 분야의 논문을 사용했습니다.

튜링 테스트 결과, 종종 선택되는 것을 확인할 수 있었습니다. 대부분의 초록은 일부 수정을 거쳐 매우 유익하고 일관성있게 작성됩니다.

### 2. Approach

#### 2.1 Overview

![overview](https://i.imgur.com/wxs5wCb.png)

결과물 예시입니다.

![example](https://i.imgur.com/PzriPcX.png)

#### 2.2 Background Knowledge

아래는 KGs의 예시입니다.

entity mention extraction and linking system 을 사용했습니다.

총 3개(Disease, Chemical, Gene) entity 타입을 가져왔습니다.

이는 Comparative Toxicogenomics Database (CTD)에서 핵심 카테고리입니다.

또한 Medical Subject Headings(MeSH)에서 Unique ID를 가져왔다고 합니다.

그렇게 MeSH Unique ID를 기반으로 모든 개체를 CTD에 추가로 연결하고 총 133개의 relation subtype을 추출했습니다. (ex. **Marker/Mechanism, Therapeutic,
 Increase Expression**)

![KGs example](https://i.imgur.com/z2BjqZS.png)

#### 2.3 Link Prediction

이제 Link Prediction을 진행할 차례입니다. 문맥상 텍스트 정보와 그래프 구조 모두 중요한 요소이기에 이 둘을 결합했습니다.

초반에는 형성된 KGs에 의미론적으로 유사한 entity의 경우 propagation을 진행했습니다.

위의 그림에서는 칼슘과 아연은 텍스트 정보와 그래프 구조면에서 유사하기에 칼슘과 CD14 분자와 neuropilin2을 새로운 이웃으로 예측합니다.

- 그래프에서 이웃간의 정보의 경우 self-attention을 통해 분포를 계산했습니다.

- 문맥정보는 LSTM을 사용했습니다.

- 두 정보의 결합 gate function은 다음과 같이 정의했습니다.

![gatefunction](https://i.imgur.com/4y7HChJ.png)

- entity와 relation의 optimze는 TransE를 사용했습니다.

#### 2.4 New Paper Writing

- 기본적인 프레임워크는 Mem2seq 모델을 사용했다고 합니다.

- 제목은 양방향 GRU를 사용하여 만들었습니다.

나머지 내용은 논문을 참고하면 좋을 것 같습니다.

- Decoder Hidden State Initialization
- Memory Network
- Reference Attention
- Generator
- Repetition Removal

### 3. Experiment

#### 3.1 Dataset

PMC Open Access Subset에서 논문 데이터를 가져왔다고 합니다.

총 1687060개의 논문을 사용했고, 30483개의 entities와 875698개의 relation을 포함한다고 합니다. 다음은 수집한 논문의 통계 자료입니다.

![statistic](https://i.imgur.com/vlHpYX5.png)

하이퍼파라미터 정보는 다음과 같습니다.

![Hyperparameters](https://i.imgur.com/HY2kEDK.png)

#### Turing Test

![Turing Test](https://i.imgur.com/GdUm55x.png)

#### 그 외 결과들

![스크린샷 2019-05-21 오후 6.10.26](https://i.imgur.com/ZQft2Ce.png)![스크린샷 2019-05-21 오후 6.10.32](https://i.imgur.com/t1nfBh9.png)![스크린샷 2019-05-21 오후 6.10.44](https://i.imgur.com/1wprFq6.png)
